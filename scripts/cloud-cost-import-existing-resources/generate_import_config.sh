#!/bin/bash
#
# Datadog Terraform Import Generator
#
# This script generates Terraform import blocks for existing Cloud Cost Management
# and Tag Pipeline resources in your Datadog account, then uses Terraform's
# -generate-config-out flag to automatically create the resource configurations.
#
# PREREQUISITES:
#   - DD_API_KEY: Your Datadog API key (required)
#   - DD_APP_KEY: Your Datadog Application key (required)
#   - DD_SITE: Your Datadog site (optional, defaults to datadoghq.com)
#   - Terraform 1.5+ (required for -generate-config-out flag)
#   - jq: JSON processor tool (required)
#
# USAGE:
#   export DD_API_KEY="your_api_key"
#   export DD_APP_KEY="your_app_key"
#   ./generate_import_config.sh [output_directory]
#
# OUTPUT FILES:
#   - provider.tf: Provider configuration
#   - imports.tf: Terraform import blocks
#   - generated_resources.tf: Auto-generated by Terraform
#
# SUPPORTED RESOURCES:
#   - AWS CUR (Cost and Usage Report) configurations
#   - Azure Usage Cost configurations
#   - GCP Usage Cost configurations
#   - Custom allocation rules
#   - Tag pipeline rulesets
#
# For more information, see: scripts/cloud-cost-import-existing-resources/README.md

set -e
set -o pipefail

# ============================================================================
# Configuration
# ============================================================================

# Output directory - defaults to current directory if not specified
OUTPUT_DIR="${1:-.}"
PROVIDER_TF="${OUTPUT_DIR}/provider.tf"
IMPORT_TF="${OUTPUT_DIR}/imports.tf"
GENERATED_TF="${OUTPUT_DIR}/generated_resources.tf"

# Datadog API configuration
DD_SITE="${DD_SITE:-datadoghq.com}"
API_BASE="https://api.${DD_SITE}"

# Color codes for terminal output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# ============================================================================
# Prerequisites Check
# ============================================================================
echo -e "${GREEN}Checking prerequisites...${NC}"

# Verify required environment variables are set
if [ -z "$DD_API_KEY" ] || [ -z "$DD_APP_KEY" ]; then
    echo -e "${RED}Error: DD_API_KEY and DD_APP_KEY environment variables must be set${NC}"
    echo ""
    echo "Please export your Datadog credentials:"
    echo "  export DD_API_KEY=\"your_api_key\""
    echo "  export DD_APP_KEY=\"your_app_key\""
    exit 1
fi

# Verify jq is installed for JSON processing
if ! command -v jq &> /dev/null; then
    echo -e "${RED}Error: jq is not installed. Please install it first.${NC}"
    echo ""
    echo "Installation instructions:"
    echo "  macOS: brew install jq"
    echo "  Linux: apt-get install jq / yum install jq"
    exit 1
fi

# Verify terraform is installed
if ! command -v terraform &> /dev/null; then
    echo -e "${RED}Error: terraform is not installed. Please install it first.${NC}"
    exit 1
fi

# Check terraform version (need 1.5+)
TF_VERSION=$(terraform version -json | jq -r '.terraform_version')
TF_MAJOR=$(echo "$TF_VERSION" | cut -d. -f1)
TF_MINOR=$(echo "$TF_VERSION" | cut -d. -f2)

if [ "$TF_MAJOR" -lt 1 ] || ([ "$TF_MAJOR" -eq 1 ] && [ "$TF_MINOR" -lt 5 ]); then
    echo -e "${RED}Error: Terraform 1.5 or later is required (found $TF_VERSION)${NC}"
    echo "The -generate-config-out flag requires Terraform 1.5+"
    exit 1
fi

# Create output directory if it doesn't exist
mkdir -p "$OUTPUT_DIR"

# ============================================================================
# Initialize Output Files
# ============================================================================

# Generate provider configuration
cat > "$PROVIDER_TF" <<'EOF'
terraform {
  required_providers {
    datadog = {
      source = "DataDog/datadog"
    }
  }
}

provider "datadog" {
  api_key = var.datadog_api_key
  app_key = var.datadog_app_key
  api_url = var.datadog_api_url
}

variable "datadog_api_key" {
  description = "Datadog API key"
  type        = string
  sensitive   = true
}

variable "datadog_app_key" {
  description = "Datadog APP key"
  type        = string
  sensitive   = true
}

variable "datadog_api_url" {
  description = "Datadog API URL"
  type        = string
  default     = "https://api.datadoghq.com"
}
EOF

# Initialize imports file
cat > "$IMPORT_TF" <<EOF
# ============================================================================
# Terraform Import Blocks for Datadog Cloud Cost Resources
# ============================================================================
#
# This file contains import blocks for existing Datadog resources.
# Run 'terraform plan -generate-config-out=generated_resources.tf' to
# automatically generate the resource configurations.
#
# Generated at: $(date)
# ============================================================================

EOF

# ============================================================================
# Helper Functions
# ============================================================================

# api_call: Makes authenticated API calls to Datadog
# Usage: api_call "/api/v2/endpoint"
api_call() {
    local endpoint="$1"
    curl -s -X GET "${API_BASE}${endpoint}" \
        -H "DD-API-KEY: ${DD_API_KEY}" \
        -H "DD-APPLICATION-KEY: ${DD_APP_KEY}" \
        -H "Accept: application/json"
}

# ============================================================================
# Fetch Resources from Datadog
# ============================================================================
echo -e "${GREEN}Fetching existing resources from Datadog...${NC}"

# Track total number of resources found
RESOURCE_COUNT=0

# ============================================================================
# AWS Cost and Usage Report (CUR) Configurations
# ============================================================================
echo -e "${YELLOW}Checking for AWS CUR configurations...${NC}"

AWS_CONFIGS=$(api_call "/api/v2/cost/aws_cur_config")
AWS_COUNT=$(echo "$AWS_CONFIGS" | jq '.data | length')

if [ "$AWS_COUNT" -gt 0 ]; then
    echo "  Found $AWS_COUNT AWS CUR configuration(s)"

    echo "$AWS_CONFIGS" | jq -r '.data[] |
"
import {
  to = datadog_aws_cur_config.aws_cur_\(.attributes.account_id | gsub("[^a-zA-Z0-9_]"; "_"))
  id = \"\(.id)\"
}
"' >> "$IMPORT_TF"

    RESOURCE_COUNT=$((RESOURCE_COUNT + AWS_COUNT))
fi

# ============================================================================
# Azure Usage Cost (UC) Configurations
# ============================================================================
echo -e "${YELLOW}Checking for Azure UC configurations...${NC}"

AZURE_RESPONSE=$(api_call "/api/v2/cost/azure_uc_config")
AZURE_IDS=$(echo "$AZURE_RESPONSE" | jq -r '.data[].id' 2>/dev/null || echo "")

if [ -n "$AZURE_IDS" ]; then
    AZURE_COUNT=$(echo "$AZURE_IDS" | wc -l | tr -d ' ')
    echo "  Found $AZURE_COUNT Azure UC configuration(s)"

    for CLOUD_ACCOUNT_ID in $AZURE_IDS; do
        AZURE_CONFIG=$(api_call "/api/v2/cost/azure_uc_config/${CLOUD_ACCOUNT_ID}")
        AZURE_ACCOUNT_ID=$(echo "$AZURE_CONFIG" | jq -r '.data.attributes.configs[0].account_id | gsub("[^a-zA-Z0-9_]"; "_")')

        cat >> "$IMPORT_TF" <<AZUREIMPORT

import {
  to = datadog_azure_uc_config.azure_uc_${AZURE_ACCOUNT_ID}
  id = "${CLOUD_ACCOUNT_ID}"
}
AZUREIMPORT
        RESOURCE_COUNT=$((RESOURCE_COUNT + 1))
    done
fi

# ============================================================================
# GCP Usage Cost (UC) Configurations
# ============================================================================
echo -e "${YELLOW}Checking for GCP UC configurations...${NC}"

GCP_RESPONSE=$(api_call "/api/v2/cost/gcp_uc_config")
GCP_IDS=$(echo "$GCP_RESPONSE" | jq -r '.data[].id' 2>/dev/null || echo "")

if [ -n "$GCP_IDS" ]; then
    GCP_COUNT=$(echo "$GCP_IDS" | wc -l | tr -d ' ')
    echo "  Found $GCP_COUNT GCP UC configuration(s)"

    for CLOUD_ACCOUNT_ID in $GCP_IDS; do
        GCP_CONFIG=$(api_call "/api/v2/cost/gcp_uc_config/${CLOUD_ACCOUNT_ID}")
        GCP_BILLING_ACCOUNT=$(echo "$GCP_CONFIG" | jq -r '.data.attributes.account_id | gsub("[^a-zA-Z0-9_]"; "_")')

        cat >> "$IMPORT_TF" <<GCPIMPORT

import {
  to = datadog_gcp_uc_config.gcp_uc_${GCP_BILLING_ACCOUNT}
  id = "${CLOUD_ACCOUNT_ID}"
}
GCPIMPORT
        RESOURCE_COUNT=$((RESOURCE_COUNT + 1))
    done
fi

# ============================================================================
# Custom Allocation Rules
# ============================================================================
echo -e "${YELLOW}Checking for custom allocation rules...${NC}"

ALLOCATION_RESPONSE=$(api_call "/api/v2/cost/arbitrary_rule" 2>/dev/null || echo '{"data":[]}')
ALLOCATION_COUNT=$(echo "$ALLOCATION_RESPONSE" | jq '.data | length' 2>/dev/null || echo "0")

if [ "$ALLOCATION_COUNT" -gt 0 ]; then
    echo "  Found $ALLOCATION_COUNT custom allocation rule(s)"

    echo "$ALLOCATION_RESPONSE" | jq -r '.data[] |
"
import {
  to = datadog_custom_allocation_rule.custom_allocation_rule_\(.attributes.rule_name | gsub("[^a-zA-Z0-9_]"; "_") | ascii_downcase)
  id = \"\(.id)\"
}
"' >> "$IMPORT_TF"

    RESOURCE_COUNT=$((RESOURCE_COUNT + ALLOCATION_COUNT))
fi

# ============================================================================
# Tag Pipeline Rulesets
# ============================================================================
echo -e "${YELLOW}Checking for tag pipeline rulesets...${NC}"

TAG_PIPELINE_RESPONSE=$(api_call "/api/v2/tags/enrichment" 2>/dev/null || echo '{"data":[]}')
TAG_PIPELINE_COUNT=$(echo "$TAG_PIPELINE_RESPONSE" | jq '.data | length' 2>/dev/null || echo "0")

if [ "$TAG_PIPELINE_COUNT" -gt 0 ]; then
    echo "  Found $TAG_PIPELINE_COUNT tag pipeline ruleset(s)"

    echo "$TAG_PIPELINE_RESPONSE" | jq -r '.data[] |
"
import {
  to = datadog_tag_pipeline_ruleset.tag_pipeline_ruleset_\(.attributes.name | gsub("[^a-zA-Z0-9_]"; "_") | ascii_downcase)_\(.id | gsub("[^a-zA-Z0-9_]"; "_"))
  id = \"\(.id)\"
}
"' >> "$IMPORT_TF"

    RESOURCE_COUNT=$((RESOURCE_COUNT + TAG_PIPELINE_COUNT))
fi

# ============================================================================
# Finalize and Generate Configuration
# ============================================================================

echo ""
echo -e "${GREEN}========================================${NC}"
echo -e "${GREEN}Import blocks generated!${NC}"
echo -e "${GREEN}========================================${NC}"
echo ""
echo "Total resources found: $RESOURCE_COUNT"
echo ""

if [ "$RESOURCE_COUNT" -eq 0 ]; then
    echo -e "${YELLOW}Warning: No resources were found${NC}"
    echo ""
    echo "This could mean:"
    echo "  - You have no existing Cloud Cost Management or Tag Pipeline resources in Datadog"
    echo "  - Your API keys don't have sufficient permissions to read these resources"
    echo "  - The API endpoints are not available for your Datadog site (${DD_SITE})"
    echo ""
    exit 0
fi

echo "Generated files:"
echo "  - ${PROVIDER_TF}"
echo "  - ${IMPORT_TF}"
echo ""

# ============================================================================
# Run Terraform to Generate Configuration
# ============================================================================

echo -e "${GREEN}Initializing Terraform...${NC}"
cd "$OUTPUT_DIR"

if ! terraform init -upgrade > /dev/null 2>&1; then
    echo -e "${RED}Error: terraform init failed${NC}"
    echo "Please check your provider configuration and try again."
    exit 1
fi

echo -e "${GREEN}Generating resource configuration from imports...${NC}"
echo ""
echo "Running: terraform plan -generate-config-out=generated_resources.tf"
echo ""

# Set terraform variables for the plan
export TF_VAR_datadog_api_key="$DD_API_KEY"
export TF_VAR_datadog_app_key="$DD_APP_KEY"
export TF_VAR_datadog_api_url="$API_BASE"

if terraform plan -generate-config-out=generated_resources.tf > /dev/null 2>&1; then
    echo ""
    echo -e "${GREEN}========================================${NC}"
    echo -e "${GREEN}Configuration generated successfully!${NC}"
    echo -e "${GREEN}========================================${NC}"
    echo ""
    echo "Generated files:"
    echo "  - ${PROVIDER_TF} (provider configuration)"
    echo "  - ${IMPORT_TF} (import blocks)"
    echo "  - ${GENERATED_TF} (resource configurations)"
    echo ""
    echo "Next steps:"
    echo ""
    echo "  1. Review ${GENERATED_TF}:"
    echo "     - Rename resources to meaningful names"
    echo "     - Adjust configurations as needed"
    echo "     - Remove any resources you don't want to manage"
    echo ""
    echo "  2. Import all resources into Terraform state:"
    echo "     terraform apply"
    echo ""
    echo "  3. Verify the import succeeded:"
    echo "     terraform plan"
    echo ""
    echo "     You should see 'No changes' if everything matches correctly."
    echo ""
    echo "  4. (Optional) Clean up the imports file:"
    echo "     After successful import, you can delete ${IMPORT_TF}"
    echo ""
else
    echo ""
    echo -e "${RED}========================================${NC}"
    echo -e "${RED}Error generating configuration${NC}"
    echo -e "${RED}========================================${NC}"
    echo ""
    echo "The terraform plan command failed. This could be due to:"
    echo "  - Provider authentication issues"
    echo "  - Network connectivity problems"
    echo "  - Invalid import block resource names"
    echo ""
    echo "Files have been generated, you can try manually:"
    echo "  cd ${OUTPUT_DIR}"
    echo "  terraform plan -generate-config-out=generated_resources.tf"
    echo ""
    exit 1
fi
